RAG Policy Chatbot (n8n + Pinecone)

This repository contains a Retrieval-Augmented Generation (RAG) chatbot built as a portfolio project, demonstrating how structured policy documents can be reliably queried using a retrieval-first AI agent.

The system is designed to always retrieve relevant policy content from a vector database before answering, avoiding hallucinations and generic responses.

âœ¨ Project Goal

The goal of this project is to demonstrate:

A clean RAG architecture using n8n as the orchestration layer

A disciplined AI agent that answers strictly from retrieved documents

Practical usage of Pinecone for vector search

Realistic customer-support policy scenarios (returns, warranty, shipping, DOA, customs)

This is not a toy chatbot â€” it is structured to behave like a real internal or customer-facing policy assistant.

ğŸ§  How It Works (High-Level)

Policy documents (Markdown files) are embedded using OpenAI embeddings.

All embeddings are stored in a single Pinecone namespace.

An AI Agent in n8n receives a user question.

The agent is explicitly instructed to:

always retrieve relevant policy chunks from Pinecone

answer only using the retrieved text

If the information is not found in the policies, the agent responds accordingly.

This ensures grounded, policy-based answers without relying on general model knowledge.

ğŸ§© Architecture Overview

The workflow is orchestrated using n8n, with clear separation between:

ingestion

retrieval

reasoning

response generation

ğŸ¤– AI Agent Configuration

The AI Agent is configured with a strict system message that enforces:

retrieval-first behavior

no use of general knowledge

policy-only answers

This is a key part of the RAG discipline demonstrated in this project.

ğŸ” Vector Retrieval Example

The Pinecone Vector Store returns relevant policy chunks (including metadata such as line ranges), which are then used by the agent to generate responses.

ğŸ“‚ Repository Structure

rag-policy-chatbot-n8n/
â”œâ”€â”€ README.md
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ RAG_Pipeline_Chat_Bot.json
â”œâ”€â”€ policies/
â”‚   â”œâ”€â”€ store_policy_overview.md
â”‚   â”œâ”€â”€ shipping_customs_restricted_items_policy.md
â”‚   â”œâ”€â”€ returns_exchanges_restocking_fees_policy.md
â”‚   â”œâ”€â”€ warranty_and_repairs_rma_policy.md
â”‚   â”œâ”€â”€ support_sla_and_dispute_resolution_policy.md
â”‚   â”œâ”€â”€ data_and_account_policy.md
â”‚   â””â”€â”€ faq.md
â””â”€â”€ docs/
    â””â”€â”€ screenshots/
        â”œâ”€â”€ workflow_overview.png
        â”œâ”€â”€ agent_node.png
        â””â”€â”€ pinecone_output.png

âš™ï¸ Technologies Used

n8n â€“ workflow orchestration and AI agent execution

Pinecone â€“ vector database for document retrieval

OpenAI Embeddings â€“ text-embedding-3-small (512-dimensional)

OpenAI Chat Model â€“ gpt-4.1-mini

Markdown â€“ policy document format

All documents are indexed into a single Pinecone namespace.

ğŸš€ How to Use

Import the workflow JSON into n8n:

workflows/RAG_Pipeline_Chat_Bot.json


Configure your own credentials in n8n:

OpenAI

Pinecone

Upload or modify policy documents if needed.

Run the workflow and interact with the chatbot.

Note: No API keys or secrets are included in this repository.

ğŸ“Œ Final Notes

This project focuses on clarity, correctness, and grounded responses, rather than UI or frontend polish.

It is intended as a technical demonstration of RAG best practices using real-world policy content.